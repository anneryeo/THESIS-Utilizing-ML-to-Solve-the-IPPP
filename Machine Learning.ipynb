{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6143b139-6ea9-41dc-b70e-f23fb53a1d79",
   "metadata": {},
   "source": [
    "# A. Importation of libraries and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df0ad8-d6c4-473a-b069-a93f2a63ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Non-standard Libaries\n",
    "from FeatureEngineering.credit_sales_machine_learning import CreditSales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848437e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Path to the pseudonimized revenues dataset\n",
    "    dataset_dir = r\"Database\\revenues_pseudonymized.xlsx\"\n",
    "    # Path to the enrollee infos\n",
    "    enrollees_dir = r\"Database\\enrollees_pseudonymized.xlsx\"\n",
    "    # Path to the machine learning model parameters\n",
    "    parameters_dir = r\"MachineLearning\\parameters.json\"\n",
    "\n",
    "    # Path to cache directory to store preprocessed dataset if needed\n",
    "    cache_dir = \"\"\n",
    "    load_cache = True\n",
    "\n",
    "    # Path to store transformer results\n",
    "    results_dir = r\"C:\\Users\\rjbel\\Python\\Data\\Thesis\\Results\"\n",
    "\n",
    "    # Class to predict\n",
    "    target_feature = 'dtp_bracket'\n",
    "    # Test size in %\n",
    "    test_size = 0.3\n",
    "\n",
    "\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c1c6e-f32a-4afa-8315-20df2b812912",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# B. Loading of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f64013-4d4d-4e4e-ba91-2d9703fb6316",
   "metadata": {},
   "source": [
    "## 1. Revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bf19c-2a62-415b-a5fb-844e763eff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenues = pd.read_excel(args.dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938baf3-c770-4cf8-afd8-4b188a1d4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af590ab2",
   "metadata": {},
   "source": [
    "## 2. Enrollees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enrollees = pd.read_excel(args.enrollees_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18e917-49a5-43ad-a698-d8c1889f5ea6",
   "metadata": {},
   "source": [
    "## 3. Credit Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d6e58-bee1-49e5-a6be-5c7677487f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CreditSales(df_revenues, df_enrollees)\n",
    "df_credit_sales = cs.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_sales.dropna(subset=['dtp_1', 'dtp_2', 'dtp_3', 'dtp_4', 'dtp_bracket'], inplace=True)\n",
    "\n",
    "# Drop plans D, E, and not enrolled\n",
    "df_credit_sales = df_credit_sales[\n",
    "    (df_credit_sales['plan_type_Plan - D'] != 1) &\n",
    "    (df_credit_sales['plan_type_Plan - E'] != 1) &\n",
    "    (df_credit_sales['plan_type_nan'] != 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788205d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3871539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Clean the column: drop NaNs and empty strings\n",
    "cleaned_days = df_credit_sales['days_elapsed_until_fully_paid']\n",
    "cleaned_days = cleaned_days.replace(\"\", np.nan).dropna()\n",
    "\n",
    "# Filter to range -300 to +300\n",
    "filtered_days = cleaned_days[(cleaned_days >= -100) & (cleaned_days <= 100)]\n",
    "\n",
    "# KDE plot\n",
    "sns.kdeplot(\n",
    "    x=filtered_days,\n",
    "    fill=False,\n",
    "    color=\"steelblue\"\n",
    ")\n",
    "\n",
    "plt.title(\"KDE Plot: Days Elapsed Until Fully Paid (-300 to +300)\")\n",
    "plt.xlabel(\"Days Elapsed\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35832508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_credit_sales = df_credit_sales.dropna(subset=['dtp_1', 'dtp_2', 'dtp_3', 'dtp_4'])\n",
    "\n",
    "# Select relevant columns\n",
    "cols = ['days_elapsed_until_fully_paid', \n",
    "        'dtp_1', 'dtp_2', 'dtp_3', 'dtp_4', \n",
    "        'dtp_avg', 'dtp_wavg', 'dtp_2_trend',\n",
    "        'dtp_3_trend', 'days_since_last_payment',\n",
    "        'credit_sale_amount', 'amount_due_cumsum',\n",
    "        'amount_paid_cumsum', 'opening_balance']\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = df_credit_sales[cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0, fmt=\".2f\")\n",
    "plt.title(\"Correlation with Days Elapsed Until Fully Paid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['school_year', 'student_id_pseudonimized', 'category_name',\n",
    "       'gross_receivables', 'amount_discounted', 'adjustments', 'due_date', 'date_fully_paid',\n",
    "       'last_payment_date', 'days_elapsed_until_fully_paid',\n",
    "       'plan_type_Plan - D', 'plan_type_Plan - E', 'plan_type_nan']\n",
    "\n",
    "df_data = df_credit_sales.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c3727",
   "metadata": {},
   "source": [
    "# C. Machine Learning Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MachineLearning.Utils.data_preparation import DataPreparer\n",
    "\n",
    "# Initialize the preparer\n",
    "preparer = DataPreparer(df_data, args.target_feature, test_size=args.test_size)\n",
    "\n",
    "# Run preprocessing\n",
    "preparer.prep_data()\n",
    "\n",
    "# Load the train/test splits\n",
    "X_train = preparer.X_train\n",
    "X_test  = preparer.X_test\n",
    "y_train = preparer.y_train\n",
    "y_test  = preparer.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MachineLearning import (\n",
    "    AdaBoostPipeline,\n",
    "    DecisionTreePipeline,\n",
    "    GaussianNaiveBayesPipeline,\n",
    "    KnearestNeighborPipeline,\n",
    "    RandomForestPipeline,\n",
    "    XGboostPipeline,\n",
    "    MultiLayerPerceptronPipeline,\n",
    "    TransformerPipeline,\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"ada_boost\": AdaBoostPipeline,\n",
    "    \"decision_tree\": DecisionTreePipeline,\n",
    "    \"gaussian_naive_bayes\": GaussianNaiveBayesPipeline,\n",
    "    \"knn\": KnearestNeighborPipeline,\n",
    "    \"random_forest\": RandomForestPipeline,\n",
    "    \"xgboost\": XGboostPipeline,\n",
    "    \"nn_mlp\": MultiLayerPerceptronPipeline,\n",
    "    #\"nn_rnn\": RecurrentNeuralNetworkPipeline,\n",
    "    #\"nn_transformer\": TransformerPipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204966ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MachineLearning.Utils.load_parameters import ParameterLoader\n",
    "\n",
    "# Load parameters from JSON\n",
    "loader = ParameterLoader(args.parameters_dir)\n",
    "\n",
    "all_results = []  # list to gather results\n",
    "\n",
    "for model_name, pipeline_class in models.items():\n",
    "    param_list = loader.get_parameters(model_name)\n",
    "\n",
    "    for param in param_list:\n",
    "        print(f\"Running {model_name} with parameters: {param}\")\n",
    "\n",
    "        pipeline = pipeline_class(X_train, X_test, y_train, y_test,\n",
    "                                  args,\n",
    "                                  param)\n",
    "\n",
    "        # Capture results from pipeline\n",
    "        result = pipeline.build_model().train().evaluation().show_results()\n",
    "\n",
    "        # Add metadata (model name + parameters)\n",
    "        result[\"model\"] = model_name\n",
    "        result[\"parameters\"] = str(param)\n",
    "\n",
    "        all_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Export to Excel\n",
    "results_df.to_excel(\"MachineLearning/Results/model_results.xlsx\", index=False)\n",
    "print(\"All results saved to model_results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
